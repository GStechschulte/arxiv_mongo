{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from bson import Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Information\n",
    "cnx = 'mongodb+srv://gabe:gabe_mongo@arxiv.xawxi.mongodb.net/test'\n",
    "# Connection to MongoDB\n",
    "client = pymongo.MongoClient(cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Math', 'Economics', 'Statistics', 'ComputerScience']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client['arxiv']\n",
    "collections = db.list_collection_names()\n",
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Math.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [{'$match': {'author.name': {'$eq': 'Richard F. Bass'}}}]\n",
    "for doc in db.Math.aggregate(pipeline):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwind = [{'$project': {'_id': 0}, \n",
    "    '$unwind': '$author.name'}]\n",
    "\n",
    "for doc in db.Math.aggregate(unwind):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title, author name, affiliation, and date published\n",
    "project = {'$project': {'_id': 0, 'title':1, 'author.name':1}}\n",
    "unwind = {'$unwind': '$author.name'}\n",
    "limit = {'$limit': 5}\n",
    "\n",
    "pipeline = [project, limit]\n",
    "\n",
    "for doc in db.Math.aggregate(pipeline):\n",
    "    print(doc)\n",
    "\n",
    "#cursor = db.Math.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by category_id, return the number of authors in a paper\n",
    "c = db.Math.aggregate([\n",
    "    {'$project': {'_id':0}},\n",
    "    #{'$unwind': '$author.name'},\n",
    "    {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "])\n",
    "\n",
    "authors = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    551\n",
       "2     50\n",
       "3      7\n",
       "4      3\n",
       "5      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n",
      "{'category': {'@term': 'math.PR'}}\n"
     ]
    }
   ],
   "source": [
    "for doc in db.Math.aggregate([\n",
    "    {'$project': {'_id':0, 'category.@term':1}},\n",
    "    {'$unwind': '$category'},\n",
    "    {'$limit': 10}\n",
    "    #{'$group': {'_id': '$category.@term', 'count': {'$sum': 1}}}\n",
    "    ]):\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db.Math.aggregate([\n",
    "    {'$project': {'_id':0}},\n",
    "    {'$unwind': '$arxiv.comment'}\n",
    "    #{'$group': {'_id': '$arxiv.comment', 'count': {'$sum': 1}}}\n",
    "])\n",
    "\n",
    "cat = pd.DataFrame(c)\n",
    "cat[:1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.ComputerScience.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db.ComputerScience.aggregate([\n",
    "    {'$project': {'_id': 0}},\n",
    "    {'$unwind': '$author.name'},\n",
    "    {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "    #{'sort': {'count': 1}}\n",
    "])\n",
    "\n",
    "authors = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "csAuthors = authors.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db.Math.aggregate([\n",
    "    {'$project': {'_id': 0}},\n",
    "    {'$unwind': '$author.name'},\n",
    "    {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "    #{'sort': {'count': 1}}\n",
    "])\n",
    "\n",
    "authors = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathAuthors = authors.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db.Statistics.aggregate([\n",
    "    {'$project': {'_id': 0, 'author.name':1}},\n",
    "    {'$unwind': '$author.name'},\n",
    "    {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "    #{'sort': {'count': 1}} ## sort is not allowed in the Atlas tier\n",
    "])\n",
    "\n",
    "authors = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Heng Lian</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Andrew Gelman</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Stephen E. Fienberg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Joseph Rynkiewicz</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Claire Lacour</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Thanh Mai Pham Ngoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Hisayuki Hara</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Cécile Durot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Yiyuan She</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Liqun Wang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _id  count\n",
       "143            Heng Lian     12\n",
       "189        Andrew Gelman      6\n",
       "75   Stephen E. Fienberg      6\n",
       "377    Joseph Rynkiewicz      5\n",
       "131        Claire Lacour      5\n",
       "..                   ...    ...\n",
       "152  Thanh Mai Pham Ngoc      1\n",
       "151        Hisayuki Hara      1\n",
       "150         Cécile Durot      1\n",
       "146           Yiyuan She      1\n",
       "407           Liqun Wang      1\n",
       "\n",
       "[408 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statAuthors = authors.sort_values(by=['count'], ascending=False)\n",
    "statAuthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db.Economics.aggregate([\n",
    "    {'$project': {'_id': 0}},\n",
    "    {'$unwind': '$author.name'},\n",
    "    {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "    #{'sort': {'count': 1}}\n",
    "])\n",
    "\n",
    "authors = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "econAuthors = authors.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in db.ComputerScience.aggregate([\n",
    "    {'$match': {'author.name': 'Kilian Q. Weinberger'}},\n",
    "    {'$project': {'title': 1, 'author.name': 1, '_id': 0}}]):\n",
    "\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Searching for Plannable Domains can Speed up Reinforcement Learning', 'author': [{'name': 'Istvan Szita'}, {'name': 'Balint Takacs'}, {'name': 'Andras Lorincz'}]}\n",
      "{'title': 'Temporal plannability by variance of the episode length', 'author': [{'name': 'Balint Takacs'}, {'name': 'Istvan Szita'}, {'name': 'Andras Lorincz'}]}\n",
      "{'title': 'Kalman-filtering using local interactions', 'author': [{'name': 'Barnabas Poczos'}, {'name': 'Andras Lorincz'}]}\n"
     ]
    }
   ],
   "source": [
    "stage_lookup = {\n",
    "    '$lookup': {\n",
    "        'from': 'Math',\n",
    "        'localField': 'author.name',\n",
    "        'foreignField': 'author.name',\n",
    "        'as': 'same_author'\n",
    "    }\n",
    "}\n",
    "\n",
    "match = {'$match': {'same_author.0': {'$exists': True}}}\n",
    "\n",
    "add_fields = {'$addFields': {\n",
    "    'author_name': 'author.name',\n",
    "    'paper_title': 'title'\n",
    "}}\n",
    "\n",
    "project = {'$project': {'_id': 0, 'author.name':1, 'title': 1}}\n",
    "\n",
    "unwind = {'$unwind': '$author.name'}\n",
    "\n",
    "group_by = {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "\n",
    "limit = {'$limit': 3}\n",
    "\n",
    "pipeline = [stage_lookup, match, project, add_fields, project, limit]\n",
    "#pipeline = [stage_lookup, match, project, unwind, group_by, limit]\n",
    "\n",
    "for doc in db.ComputerScience.aggregate(pipeline):\n",
    "    print(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = {'$group':\n",
    "            {\n",
    "                '_id': {'title': '$title'},\n",
    "                'authors': {'$cnt': 'author.names'}\n",
    "            }}\n",
    "\n",
    "for doc in db.ComputerScience.aggregate([group]):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in db.ComputerScience.aggregate([\n",
    "    {'$group': {'_id': 'author.names', 'count': {'$sum': 1}}}]):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.ComputerScience.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.ComputerScience.aggregate([\n",
    "    {'$group': {\n",
    "        '_id': {\n",
    "            'year': {'$year': '$published'}\n",
    "        }\n",
    "    }\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.ComputerScience.aggregate([\n",
    "    {'$project': {\n",
    "        '_id': {\n",
    "            'year': {'$dateFromString': 'published', 'format': '%Y/%m/%d'}\n",
    "        }\n",
    "    }\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex = {'title', {'title': {'$regex': '^Baye'}}}\n",
    "\n",
    "db.Statistics.distinct('title', {'title': {'$regex': '^Baye'}})\n",
    "#db.Statistics.aggregate([regex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primarily a Bayesian - how many papers mention \"Bayes / Bayesian\" in their title\n",
    "for doc in db.Statistics.aggregate([\n",
    "    {'$project': {'_id': 0,\n",
    "                  'title': 1,\n",
    "                  'author.name': 1}},\n",
    "    #{'$unwind': '$author.name'},\n",
    "    {'$match': {'title': {'$regex': '^Bayes'}}}\n",
    "]):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of authors for a given paper\n",
    "size = {\n",
    "    '$addFields': {\n",
    "        'author_count': {\n",
    "            '$size': '$author'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "project = {\n",
    "    '$project': {'_id': 0, 'title':1}\n",
    "}\n",
    "\n",
    "pipeline = [size, project]\n",
    "\n",
    "for doc in db.Statistics.aggregate(pipeline):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('61713010a77f760e9fcdf804'), 'id': 'http://arxiv.org/abs/0707.3013v1', 'updated': '2007-07-20T08:23:41Z', 'published': '2007-07-20T08:23:41Z', 'title': 'Application of probabilistic PCR5 Fusion Rule for Multisensor Target\\n  Tracking', 'summary': 'This paper defines and implements a non-Bayesian fusion rule for combining\\ndensities of probabilities estimated by local (non-linear) filters for tracking\\na moving target by passive sensors. This rule is the restriction to a strict\\nprobabilistic paradigm of the recent and efficient Proportional Conflict\\nRedistribution rule no 5 (PCR5) developed in the DSmT framework for fusing\\nbasic belief assignments. A sampling method for probabilistic PCR5 (p-PCR5) is\\ndefined. It is shown that p-PCR5 is more robust to an erroneous modeling and\\nallows to keep the modes of local densities and preserve as much as possible\\nthe whole information inherent to each densities to combine. In particular,\\np-PCR5 is able of maintaining multiple hypotheses/modes after fusion, when the\\nhypotheses are too distant in regards to their deviations. This new p-PCR5 rule\\nhas been tested on a simple example of distributed non-linear filtering\\napplication to show the interest of such approach for future developments. The\\nnon-linear distributed filter is implemented through a basic particles\\nfiltering technique. The results obtained in our simulations show the ability\\nof this p-PCR5-based filter to track the target even when the models are not\\nwell consistent in regards to the initialization and real cinematic.', 'author': [{'name': 'Alois Kirchner', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'DGA/CTA/DT/GIP'}}, {'name': 'Frederic Dambreville', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'DGA/CTA/DT/GIP'}}, {'name': 'Francis Celeste', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'DGA/CTA/DT/GIP'}}, {'name': 'Jean Dezert'}, {'name': 'Florentin Smarandache'}], 'link': [{'@href': 'http://arxiv.org/abs/0707.3013v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0707.3013v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf80c'), 'id': 'http://arxiv.org/abs/0708.4350v1', 'updated': '2007-08-31T14:08:51Z', 'published': '2007-08-31T14:08:51Z', 'title': 'Random-set methods identify distinct aspects of the enrichment signal in\\n  gene-set analysis', 'summary': \"A prespecified set of genes may be enriched, to varying degrees, for genes\\nthat have altered expression levels relative to two or more states of a cell.\\nKnowing the enrichment of gene sets defined by functional categories, such as\\ngene ontology (GO) annotations, is valuable for analyzing the biological\\nsignals in microarray expression data. A common approach to measuring\\nenrichment is by cross-classifying genes according to membership in a\\nfunctional category and membership on a selected list of significantly altered\\ngenes. A small Fisher's exact test $p$-value, for example, in this $2\\\\times2$\\ntable is indicative of enrichment. Other category analysis methods retain the\\nquantitative gene-level scores and measure significance by referring a\\ncategory-level statistic to a permutation distribution associated with the\\noriginal differential expression problem. We describe a class of random-set\\nscoring methods that measure distinct components of the enrichment signal. The\\nclass includes Fisher's test based on selected genes and also tests that\\naverage gene-level evidence across the category. Averaging and selection\\nmethods are compared empirically using Affymetrix data on expression in\\nnasopharyngeal cancer tissue, and theoretically using a location model of\\ndifferential expression. We find that each method has a domain of superiority\\nin the state space of enrichment problems, and that both methods have benefits\\nin practice. Our analysis also addresses two problems related to\\nmultiple-category inference, namely, that equally enriched categories are not\\ndetected with equal probability if they are of different sizes, and also that\\nthere is dependence among category statistics owing to shared genes. Random-set\\nenrichment calculations do not require Monte Carlo for implementation. They are\\nmade available in the R package allez.\", 'author': [{'name': 'Michael A. Newton'}, {'name': 'Fernando A. Quintana'}, {'name': 'Johan A. den Boon'}, {'name': 'Srikumar Sengupta'}, {'name': 'Paul Ahlquist'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/07-AOAS104'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/07-AOAS104', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0708.4350v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0708.4350v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published at http://dx.doi.org/10.1214/07-AOAS104 in the Annals of\\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Annals of Applied Statistics 2007, Vol. 1, No. 1, 85-106'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf817'), 'id': 'http://arxiv.org/abs/0710.0559v1', 'updated': '2007-10-02T15:22:32Z', 'published': '2007-10-02T15:22:32Z', 'title': 'Panel and Pseudo-Panel Estimation of Cross-Sectional and Time Series\\n  Elasticities of Food Consumption: The Case of American and Polish Data', 'summary': 'The problem addressed in this article is the bias to income and expenditure\\nelasticities estimated on pseudo-panel data caused by measurement error and\\nunobserved heterogeneity. We gauge empirically these biases by comparing\\ncross-sectional, pseudo-panel and true panel data from both Polish and American\\nexpenditure surveys. Our results suggest that unobserved heterogeneity imparts\\na downward bias to cross-section estimates of income elasticities of at-home\\nfood expenditures and an upward bias to estimates of income elasticities of\\naway-from-home food expenditures. \"Within\" and first-difference estimators\\nsuffer less bias, but only if the effects of measurement error are accounted\\nfor with instrumental variables.', 'author': [{'name': 'François Gardes', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'CERMSEM'}}, {'name': 'Greg Duncan', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'SAMOS'}}, {'name': 'Patrice Gaubert', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'SAMOS'}}, {'name': 'Marc Gurgand', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'DELTA'}}, {'name': 'Christophe Starzec', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'TEAM'}}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '12 p'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Journal of Business & Economic Statistics 23, 2 (2005) 242-253'}, 'link': [{'@href': 'http://arxiv.org/abs/0710.0559v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0710.0559v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf818'), 'id': 'http://arxiv.org/abs/0710.0849v1', 'updated': '2007-10-03T17:38:00Z', 'published': '2007-10-03T17:38:00Z', 'title': 'Decomposition of variance in terms of conditional means', 'summary': \"We test against two different sets of data an apparently new approach to the\\nanalysis of the variance of a numerical variable which depends on qualitative\\ncharacters. We suggest that this approach be used to complement other existing\\ntechniques to study the interdependence of the variables involved. According to\\nour method the variance is expressed as a sum of orthogonal components,\\nobtained as differences of conditional means, with respect to the qualitative\\ncharacters. The resulting expression for the variance depends on the ordering\\nin which the characters are considered. We suggest an algorithm which leads to\\nan ordering which is deemed natural. The first set of data concerns the score\\nachieved by a population of students, on an entrance examination, based on a\\nmultiple choice test with 30 questions. In this case the qualitative characters\\nare dyadic and correspond to correct or incorrect answer to each question. The\\nsecond set of data concerns the delay in obtaining the degree for a population\\nof graduates of Italian universities. The variance in this case is analyzed\\nwith respect to a set of seven specific qualitative characters of the\\npopulation studied (gender, previous education, working condition, parent's\\neducational level, field of study, etc.)\", 'author': [{'name': \"Alessandro Figa' Talamanca\"}, {'name': 'Angelo Guerriero'}, {'name': 'Alberto Leone'}, {'name': 'Gian Piero Mignoli'}, {'name': 'Enrico Rogora'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '3 figures'}, 'link': [{'@href': 'http://arxiv.org/abs/0710.0849v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0710.0849v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf822'), 'id': 'http://arxiv.org/abs/0711.3687v3', 'updated': '2008-11-11T08:43:34Z', 'published': '2007-11-23T14:49:04Z', 'title': 'Residual-based localization and quantification of peaks in x-ray\\n  diffractograms', 'summary': 'We consider data consisting of photon counts of diffracted x-ray radiation as\\na function of the angle of diffraction. The problem is to determine the\\npositions, powers and shapes of the relevant peaks. An additional difficulty is\\nthat the power of the peaks is to be measured from a baseline which itself must\\nbe identified. Most methods of de-noising data of this kind do not explicitly\\ntake into account the modality of the final estimate. The residual-based\\nprocedure we propose uses the so-called taut string method, which minimizes the\\nnumber of peaks subject to a tube constraint on the integrated data. The\\nbaseline is identified by combining the result of the taut string with an\\nestimate of the first derivative of the baseline obtained using a weighted\\nsmoothing spline. Finally, each individual peak is expressed as the finite sum\\nof kernels chosen from a parametric family.', 'author': [{'name': 'P. L. Davies'}, {'name': 'U. Gather'}, {'name': 'M. Meise'}, {'name': 'D. Mergel'}, {'name': 'T. Mildenberger'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/08-AOAS181'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/08-AOAS181', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0711.3687v3', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0711.3687v3', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published in at http://dx.doi.org/10.1214/08-AOAS181 the Annals of\\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Annals of Applied Statistics 2008, Vol. 2, No. 3, 861-886'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf876'), 'id': 'http://arxiv.org/abs/0807.4658v1', 'updated': '2008-07-29T13:40:23Z', 'published': '2008-07-29T13:40:23Z', 'title': 'Unsupervised empirical Bayesian multiple testing with external\\n  covariates', 'summary': 'In an empirical Bayesian setting, we provide a new multiple testing method,\\nuseful when an additional covariate is available, that influences the\\nprobability of each null hypothesis being true. We measure the posterior\\nsignificance of each test conditionally on the covariate and the data, leading\\nto greater power. Using covariate-based prior information in an unsupervised\\nfashion, we produce a list of significant hypotheses which differs in length\\nand order from the list obtained by methods not taking covariate-information\\ninto account. Covariate-modulated posterior probabilities of each null\\nhypothesis are estimated using a fast approximate algorithm. The new method is\\napplied to expression quantitative trait loci (eQTL) data.', 'author': [{'name': 'Egil Ferkingstad'}, {'name': 'Arnoldo Frigessi'}, {'name': 'Håvard Rue'}, {'name': 'Gudmar Thorleifsson'}, {'name': 'Augustine Kong'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/08-AOAS158'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/08-AOAS158', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0807.4658v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0807.4658v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published in at http://dx.doi.org/10.1214/08-AOAS158 the Annals of\\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Annals of Applied Statistics 2008, Vol. 2, No. 2, 714-735'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf898'), 'id': 'http://arxiv.org/abs/0901.3494v1', 'updated': '2009-01-22T15:12:59Z', 'published': '2009-01-22T15:12:59Z', 'title': 'Interpreting self-organizing maps through space--time data models', 'summary': 'Self-organizing maps (SOMs) are a technique that has been used with\\nhigh-dimensional data vectors to develop an archetypal set of states (nodes)\\nthat span, in some sense, the high-dimensional space. Noteworthy applications\\ninclude weather states as described by weather variables over a region and\\nspeech patterns as characterized by frequencies in time. The SOM approach is\\nessentially a neural network model that implements a nonlinear projection from\\na high-dimensional input space to a low-dimensional array of neurons. In the\\nprocess, it also becomes a clustering technique, assigning to any vector in the\\nhigh-dimensional data space the node (neuron) to which it is closest (using,\\nsay, Euclidean distance) in the data space. The number of nodes is thus equal\\nto the number of clusters. However, the primary use for the SOM is as a\\nrepresentation technique, that is, finding a set of nodes which\\nrepresentatively span the high-dimensional space. These nodes are typically\\ndisplayed using maps to enable visualization of the continuum of the data\\nspace. The technique does not appear to have been discussed in the statistics\\nliterature so it is our intent here to bring it to the attention of the\\ncommunity. The technique is implemented algorithmically through a training set\\nof vectors. However, through the introduction of stochasticity in the form of a\\nspace--time process model, we seek to illuminate and interpret its performance\\nin the context of application to daily data collection. That is, the observed\\ndaily state vectors are viewed as a time series of multivariate process\\nrealizations which we try to understand under the dimension reduction achieved\\nby the SOM procedure.', 'author': [{'name': 'Huiyan Sang'}, {'name': 'Alan E. Gelfand'}, {'name': 'Chris Lennard'}, {'name': 'Gabriele Hegerl'}, {'name': 'Bruce Hewitson'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/08-AOAS174'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/08-AOAS174', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0901.3494v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0901.3494v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published in at http://dx.doi.org/10.1214/08-AOAS174 the Annals of\\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Annals of Applied Statistics 2008, Vol. 2, No. 4, 1194-1216'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf8a4'), 'id': 'http://arxiv.org/abs/0901.4213v1', 'updated': '2009-01-27T10:08:58Z', 'published': '2009-01-27T10:08:58Z', 'title': 'State-space based mass event-history model I: many decision-making\\n  agents with one target', 'summary': \"A dynamic decision-making system that includes a mass of indistinguishable\\nagents could manifest impressive heterogeneity. This kind of nonhomogeneity is\\npostulated to result from macroscopic behavioral tactics employed by almost all\\ninvolved agents. A State-Space Based (SSB) mass event-history model is\\ndeveloped here to explore the potential existence of such macroscopic\\nbehaviors. By imposing an unobserved internal state-space variable into the\\nsystem, each individual's event-history is made into a composition of a common\\nstate duration and an individual specific time to action. With the common state\\nmodeling of the macroscopic behavior, parametric statistical inferences are\\nderived under the current-status data structure and conditional independence\\nassumptions. Identifiability and computation related problems are also\\naddressed. From the dynamic perspectives of system-wise heterogeneity, this SSB\\nmass event-history model is shown to be very distinct from a random effect\\nmodel via the Principle Component Analysis (PCA) in a numerical experiment.\\nReal data showing the mass invasion by two species of parasitic nematode into\\ntwo species of host larvae are also analyzed. The analysis results not only are\\nfound coherent in the context of the biology of the nematode as a parasite, but\\nalso include new quantitative interpretations.\", 'author': [{'name': 'Hsieh Fushing'}, {'name': 'Li Zhu'}, {'name': 'David I. Shapiro-Ilan'}, {'name': 'James F. Campbell'}, {'name': 'Edwin E. Lewis'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/08-AOAS189'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/08-AOAS189', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0901.4213v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0901.4213v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published in at http://dx.doi.org/10.1214/08-AOAS189 the Annals of\\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Annals of Applied Statistics 2008, Vol. 2, No. 4, 1503-1522'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf8af'), 'id': 'http://arxiv.org/abs/0904.0317v1', 'updated': '2009-04-02T06:26:30Z', 'published': '2009-04-02T06:26:30Z', 'title': 'Integrating Remote Sensing, GIS and Prediction Models to Monitor the\\n  Deforestation and Erosion in Peten Reserve, Guatemala', 'summary': 'This contribution provides a strategy for studying and modelling the\\ndeforestation and soil deterioration in the natural forest reserve of Peten,\\nGuatemala, using a poor spatial database. A Multispectral Image Processing of\\nSpot and TM Landsat data permits to understand the behaviour of the past land\\ncover dynamics; a multi-temporal analysis of Normalized Difference Vegetation\\nand Hydric Stress index, most informative RGB (according to statistical\\ncriteria) and Principal Components, points out the importance and the direction\\nof environmental impacts. We gain from the Remote Sensing images new\\nenvironmental criteria (distance from roads, oil pipe-line, DEM, etc.) which\\ninfluence the spatial allocation of predicted land cover probabilities. We are\\ncomparing the results of different prospective approaches (Markov Chains, Multi\\nCriteria Evaluation and Cellular Automata; Neural Networks) analysing the\\nresidues for improving the final model of future deforestation risk.', 'author': [{'name': 'Roberto Bruno', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'DICMA'}}, {'name': 'Marco Follador', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'DICMA, GEODE'}}, {'name': 'Martin Paegelow', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'GEODE'}}, {'name': 'Fernanda Renno', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'GEODE'}}, {'name': 'Nathalie Villa', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'GRIMM'}}], 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': \"IAMG'2006 Annual Conference on Quantitative Geology from Multiple\\n  Sources, Li\\\\`ege : Belgique (2006)\"}, 'link': [{'@href': 'http://arxiv.org/abs/0904.0317v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0904.0317v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf8b7'), 'id': 'http://arxiv.org/abs/0905.2544v1', 'updated': '2009-05-15T13:08:11Z', 'published': '2009-05-15T13:08:11Z', 'title': 'Streaming motion in Leo I', 'summary': 'Whether a dwarf spheroidal galaxy is in equilibrium or being tidally\\ndisrupted by the Milky Way is an important question for the study of its dark\\nmatter content and distribution. This question is investigated using 328 recent\\nobservations from the dwarf spheroidal Leo I. For Leo I, tidal disruption is\\ndetected, at least for stars sufficiently far from the center, but the effect\\nappears to be quite modest. Statistical tools include isotonic and split point\\nestimators, asymptotic theory, and resampling methods.', 'author': [{'name': 'Bodhisattva Sen'}, {'name': 'Moulinath Banerjee'}, {'name': 'Michael Woodroofe'}, {'name': 'Mario Mateo'}, {'name': 'Matthew Walker'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/08-AOAS211'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/08-AOAS211', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0905.2544v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0905.2544v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published in at http://dx.doi.org/10.1214/08-AOAS211 the Annals of\\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Annals of Applied Statistics 2009, Vol. 3, No. 1, 96-116'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('61713010a77f760e9fcdf8b8'), 'id': 'http://arxiv.org/abs/0905.2547v1', 'updated': '2009-05-15T13:53:02Z', 'published': '2009-05-15T13:53:02Z', 'title': 'Statistical analysis of stellar evolution', 'summary': 'Color-Magnitude Diagrams (CMDs) are plots that compare the magnitudes\\n(luminosities) of stars in different wavelengths of light (colors). High\\nnonlinear correlations among the mass, color, and surface temperature of newly\\nformed stars induce a long narrow curved point cloud in a CMD known as the main\\nsequence. Aging stars form new CMD groups of red giants and white dwarfs. The\\nphysical processes that govern this evolution can be described with\\nmathematical models and explored using complex computer models. These\\ncalculations are designed to predict the plotted magnitudes as a function of\\nparameters of scientific interest, such as stellar age, mass, and metallicity.\\nHere, we describe how we use the computer models as a component of a complex\\nlikelihood function in a Bayesian analysis that requires sophisticated\\ncomputing, corrects for contamination of the data by field stars, accounts for\\ncomplications caused by unresolved binary-star systems, and aims to compare\\ncompeting physics-based computer models of stellar evolution.', 'author': [{'name': 'David A. van Dyk'}, {'name': 'Steven DeGennaro'}, {'name': 'Nathan Stein'}, {'name': 'William H. Jefferys'}, {'name': 'Ted von Hippel'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/08-AOAS219'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/08-AOAS219', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0905.2547v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0905.2547v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published in at http://dx.doi.org/10.1214/08-AOAS219 the Annals of\\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Annals of Applied Statistics 2009, Vol. 3, No. 1, 117-143'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.AP', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf8e9'), 'id': 'http://arxiv.org/abs/0909.4395v1', 'updated': '2009-09-24T09:35:10Z', 'published': '2009-09-24T09:35:10Z', 'title': 'Initialization Free Graph Based Clustering', 'summary': \"This paper proposes an original approach to cluster multi-component data\\nsets, including an estimation of the number of clusters. From the construction\\nof a minimal spanning tree with Prim's algorithm, and the assumption that the\\nvertices are approximately distributed according to a Poisson distribution, the\\nnumber of clusters is estimated by thresholding the Prim's trajectory. The\\ncorresponding cluster centroids are then computed in order to initialize the\\ngeneralized Lloyd's algorithm, also known as $K$-means, which allows to\\ncircumvent initialization problems. Some results are derived for evaluating the\\nfalse positive rate of our cluster detection algorithm, with the help of\\napproximations relevant in Euclidean spaces. Metrics used for measuring\\nsimilarity between multi-dimensional data points are based on symmetrical\\ndivergences. The use of these informational divergences together with the\\nproposed method leads to better results, compared to other clustering methods\\nfor the problem of astrophysical data processing. Some applications of this\\nmethod in the multi/hyper-spectral imagery domain to a satellite view of Paris\\nand to an image of the Mars planet are also presented. In order to demonstrate\\nthe usefulness of divergences in our problem, the method with informational\\ndivergence as similarity measure is compared with the same method using\\nclassical metrics. In the astrophysics application, we also compare the method\\nwith the spectral clustering algorithms.\", 'author': [{'name': 'Laurent Galluccio', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'GIPSA-lab'}}, {'name': 'Olivier J. J. Michel', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'GIPSA-lab'}}, {'name': 'Pierre Comon', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'CASSIOPEE'}}, {'name': 'Eric Slezak', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'CASSIOPEE'}}, {'name': 'Alfred O. Hero'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '16 pages'}, 'link': [{'@href': 'http://arxiv.org/abs/0909.4395v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0909.4395v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf8f6'), 'id': 'http://arxiv.org/abs/0912.3211v1', 'updated': '2009-12-16T17:51:39Z', 'published': '2009-12-16T17:51:39Z', 'title': 'Multi-Way, Multi-View Learning', 'summary': 'We extend multi-way, multivariate ANOVA-type analysis to cases where one\\ncovariate is the view, with features of each view coming from different,\\nhigh-dimensional domains. The different views are assumed to be connected by\\nhaving paired samples; this is a common setup in recent bioinformatics\\nexperiments, of which we analyze metabolite profiles in different conditions\\n(disease vs. control and treatment vs. untreated) in different tissues (views).\\nWe introduce a multi-way latent variable model for this new task, by extending\\nthe generative model of Bayesian canonical correlation analysis (CCA) both to\\ntake multi-way covariate information into account as population priors, and by\\nreducing the dimensionality by an integrated factor analysis that assumes the\\nmetabolites to come in correlated groups.', 'author': [{'name': 'Ilkka Huopaniemi'}, {'name': 'Tommi Suvitaival'}, {'name': 'Janne Nikkilä'}, {'name': 'Matej Orešič'}, {'name': 'Samuel Kaski'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '9 pages, 4 figures'}, 'link': [{'@href': 'http://arxiv.org/abs/0912.3211v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0912.3211v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf91d'), 'id': 'http://arxiv.org/abs/1010.2770v1', 'updated': '2010-10-13T20:48:30Z', 'published': '2010-10-13T20:48:30Z', 'title': 'Online Multiple Kernel Learning for Structured Prediction', 'summary': 'Despite the recent progress towards efficient multiple kernel learning (MKL),\\nthe structured output case remains an open research front. Current approaches\\ninvolve repeatedly solving a batch learning problem, which makes them\\ninadequate for large scale scenarios. We propose a new family of online\\nproximal algorithms for MKL (as well as for group-lasso and variants thereof),\\nwhich overcomes that drawback. We show regret, convergence, and generalization\\nbounds for the proposed method. Experiments on handwriting recognition and\\ndependency parsing testify for the successfulness of the approach.', 'author': [{'name': 'Andre F. T. Martins'}, {'name': 'Mario A. T. Figueiredo'}, {'name': 'Pedro M. Q. Aguiar'}, {'name': 'Noah A. Smith'}, {'name': 'Eric P. Xing'}], 'link': [{'@href': 'http://arxiv.org/abs/1010.2770v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1010.2770v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf94b'), 'id': 'http://arxiv.org/abs/1108.1483v2', 'updated': '2012-02-07T15:59:00Z', 'published': '2011-08-06T14:02:44Z', 'title': 'Algebraic Geometric Comparison of Probability Distributions', 'summary': 'We propose a novel algebraic framework for treating probability distributions\\nrepresented by their cumulants such as the mean and covariance matrix. As an\\nexample, we consider the unsupervised learning problem of finding the subspace\\non which several probability distributions agree. Instead of minimizing an\\nobjective function involving the estimated cumulants, we show that by treating\\nthe cumulants as elements of the polynomial ring we can directly solve the\\nproblem, at a lower computational cost and with higher accuracy. Moreover, the\\nalgebraic viewpoint on probability distributions allows us to invoke the theory\\nof Algebraic Geometry, which we demonstrate in a compact proof for an\\nidentifiability criterion.', 'author': [{'name': 'Franz J. Kiraly'}, {'name': 'Paul von Buenau'}, {'name': 'Frank C. Meinecke'}, {'name': 'Duncan A. J. Blythe'}, {'name': 'Klaus-Robert Mueller'}], 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Journal of Machine Learning Research 13(Mar):855-903. 2012'}, 'link': [{'@href': 'http://arxiv.org/abs/1108.1483v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1108.1483v2', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf94d'), 'id': 'http://arxiv.org/abs/1108.4324v3', 'updated': '2014-10-26T10:19:56Z', 'published': '2011-08-22T14:12:11Z', 'title': 'Sparse Estimation using Bayesian Hierarchical Prior Modeling for Real\\n  and Complex Linear Models', 'summary': 'In sparse Bayesian learning (SBL), Gaussian scale mixtures (GSMs) have been\\nused to model sparsity-inducing priors that realize a class of concave penalty\\nfunctions for the regression task in real-valued signal models. Motivated by\\nthe relative scarcity of formal tools for SBL in complex-valued models, this\\npaper proposes a GSM model - the Bessel K model - that induces concave penalty\\nfunctions for the estimation of complex sparse signals. The properties of the\\nBessel K model are analyzed when it is applied to Type I and Type II\\nestimation. This analysis reveals that, by tuning the parameters of the mixing\\npdf different penalty functions are invoked depending on the estimation type\\nused, the value of the noise variance, and whether real or complex signals are\\nestimated. Using the Bessel K model, we derive a sparse estimator based on a\\nmodification of the expectation-maximization algorithm formulated for Type II\\nestimation. The estimator includes as a special instance the algorithms\\nproposed by Tipping and Faul [1] and by Babacan et al. [2]. Numerical results\\nshow the superiority of the proposed estimator over these state-of-the-art\\nestimators in terms of convergence speed, sparseness, reconstruction error, and\\nrobustness in low and medium signal-to-noise ratio regimes.', 'author': [{'name': 'Niels Lovmand Pedersen'}, {'name': 'Carles Navarro Manchón'}, {'name': 'Mihai-Alin Badiu'}, {'name': 'Dmitriy Shutin'}, {'name': 'Bernard Henri Fleury'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1016/j.sigpro.2015.03.013'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1016/j.sigpro.2015.03.013', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/1108.4324v3', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1108.4324v3', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'The paper provides a new comprehensive analysis of the theoretical\\n  foundations of the proposed estimators. Minor modification of the title'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Signal Processing 115 (2015) 94-109'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf96e'), 'id': 'http://arxiv.org/abs/1202.2169v3', 'updated': '2012-07-27T19:53:58Z', 'published': '2012-02-10T03:06:07Z', 'title': 'High Dimensional Semiparametric Gaussian Copula Graphical Models', 'summary': \"In this paper, we propose a semiparametric approach, named nonparanormal\\nskeptic, for efficiently and robustly estimating high dimensional undirected\\ngraphical models. To achieve modeling flexibility, we consider Gaussian Copula\\ngraphical models (or the nonparanormal) as proposed by Liu et al. (2009). To\\nachieve estimation robustness, we exploit nonparametric rank-based correlation\\ncoefficient estimators, including Spearman's rho and Kendall's tau. In high\\ndimensional settings, we prove that the nonparanormal skeptic achieves the\\noptimal parametric rate of convergence in both graph and parameter estimation.\\nThis celebrating result suggests that the Gaussian copula graphical models can\\nbe used as a safe replacement of the popular Gaussian graphical models, even\\nwhen the data are truly Gaussian. Besides theoretical analysis, we also conduct\\nthorough numerical simulations to compare different estimators for their graph\\nrecovery performance under both ideal and noisy settings. The proposed methods\\nare then applied on a large-scale genomic dataset to illustrate their empirical\\nusefulness. The R language software package huge implementing the proposed\\nmethods is available on the Comprehensive R Archive Network: http://cran.\\nr-project.org/.\", 'author': [{'name': 'Han Liu'}, {'name': 'Fang Han'}, {'name': 'Ming Yuan'}, {'name': 'John Lafferty'}, {'name': 'Larry Wasserman'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '34 pages, 10 figures; the Annals of Statistics, 2012'}, 'link': [{'@href': 'http://arxiv.org/abs/1202.2169v3', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1202.2169v3', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf999'), 'id': 'http://arxiv.org/abs/1212.6936v1', 'updated': '2012-12-31T17:56:08Z', 'published': '2012-12-31T17:56:08Z', 'title': 'Blind Analysis of EGM Signals: Sparsity-Aware Formulation', 'summary': 'This technical note considers the problems of blind sparse learning and\\ninference of electrogram (EGM) signals under atrial fibrillation (AF)\\nconditions. First of all we introduce a mathematical model for the observed\\nsignals that takes into account the multiple foci typically appearing inside\\nthe heart during AF. Then we propose a reconstruction model based on a fixed\\ndictionary and discuss several alternatives for choosing the dictionary. In\\norder to obtain a sparse solution that takes into account the biological\\nrestrictions of the problem, a first alternative is using LASSO regularization\\nfollowed by a post-processing stage that removes low amplitude coefficients\\nviolating the refractory period characteristic of cardiac cells. As an\\nalternative we propose a novel regularization term, called cross products LASSO\\n(CP-LASSO), that is able to incorporate the biological constraints directly\\ninto the optimization problem. Unfortunately, the resulting problem is\\nnon-convex, but we show how it can be solved efficiently in an approximated way\\nmaking use of successive convex approximations (SCA). Finally, spectral\\nanalysis is performed on the clean activation sequence obtained from the sparse\\nlearning stage in order to estimate the number of latent foci and their\\nfrequencies. Simulations on synthetic and real data are provided to validate\\nthe proposed approach.', 'author': [{'name': 'David Luengo'}, {'name': 'Javier Via'}, {'name': 'Sandra Monzon'}, {'name': 'Tom Trigano'}, {'name': 'Antonio Artes-Rodriguez'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '29 pages, 1 figure'}, 'link': [{'@href': 'http://arxiv.org/abs/1212.6936v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1212.6936v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9a2'), 'id': 'http://arxiv.org/abs/1301.6915v2', 'updated': '2013-04-25T23:39:47Z', 'published': '2013-01-29T13:01:22Z', 'title': 'An Impossibility Result for High Dimensional Supervised Learning', 'summary': 'We study high-dimensional asymptotic performance limits of binary supervised\\nclassification problems where the class conditional densities are Gaussian with\\nunknown means and covariances and the number of signal dimensions scales faster\\nthan the number of labeled training samples. We show that the Bayes error,\\nnamely the minimum attainable error probability with complete distributional\\nknowledge and equally likely classes, can be arbitrarily close to zero and yet\\nthe limiting minimax error probability of every supervised learning algorithm\\nis no better than a random coin toss. In contrast to related studies where the\\nclassification difficulty (Bayes error) is made to vanish, we hold it constant\\nwhen taking high-dimensional limits. In contrast to VC-dimension based minimax\\nlower bounds that consider the worst case error probability over all\\ndistributions that have a fixed Bayes error, our worst case is over the family\\nof Gaussian distributions with constant Bayes error. We also show that a\\nnontrivial asymptotic minimax error probability can only be attained for\\nparametric subsets of zero measure (in a suitable measure space). These results\\nexpose the fundamental importance of prior knowledge and suggest that unless we\\nimpose strong structural constraints, such as sparsity, on the parametric\\nspace, supervised learning may be ineffective in high dimensional small sample\\nsettings.', 'author': [{'name': 'Mohammad Hossein Rohban'}, {'name': 'Prakash Ishwar'}, {'name': 'Birant Orten'}, {'name': 'William C. Karl'}, {'name': 'Venkatesh Saligrama'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1109/ITW.2013.6691252'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1109/ITW.2013.6691252', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/1301.6915v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1301.6915v2', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'This paper was submitted to the IEEE Information Theory Workshop\\n  (ITW) 2013 on April 23, 2013'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9a3'), 'id': 'http://arxiv.org/abs/1302.0256v1', 'updated': '2013-02-01T19:18:11Z', 'published': '2013-02-01T19:18:11Z', 'title': 'Regression shrinkage and grouping of highly correlated predictors with\\n  HORSES', 'summary': 'Identifying homogeneous subgroups of variables can be challenging in high\\ndimensional data analysis with highly correlated predictors. We propose a new\\nmethod called Hexagonal Operator for Regression with Shrinkage and Equality\\nSelection, HORSES for short, that simultaneously selects positively correlated\\nvariables and identifies them as predictive clusters. This is achieved via a\\nconstrained least-squares problem with regularization that consists of a linear\\ncombination of an L_1 penalty for the coefficients and another L_1 penalty for\\npairwise differences of the coefficients. This specification of the penalty\\nfunction encourages grouping of positively correlated predictors combined with\\na sparsity solution. We construct an efficient algorithm to implement the\\nHORSES procedure. We show via simulation that the proposed method outperforms\\nother variable selection methods in terms of prediction error and parsimony.\\nThe technique is demonstrated on two data sets, a small data set from analysis\\nof soil in Appalachia, and a high dimensional data set from a near infrared\\n(NIR) spectroscopy study, showing the flexibility of the methodology.', 'author': [{'name': 'Woncheol Jang'}, {'name': 'Johan Lim'}, {'name': 'Nicole A. Lazar'}, {'name': 'Ji Meng Loh'}, {'name': 'Donghyeon Yu'}], 'link': [{'@href': 'http://arxiv.org/abs/1302.0256v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1302.0256v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': '62J07, 62P10', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9a5'), 'id': 'http://arxiv.org/abs/1302.2969v1', 'updated': '2013-02-13T02:11:37Z', 'published': '2013-02-13T02:11:37Z', 'title': 'Towards Identification of Relevant Variables in the observed Aerosol\\n  Optical Depth Bias between MODIS and AERONET observations', 'summary': 'Measurements made by satellite remote sensing, Moderate Resolution Imaging\\nSpectroradiometer (MODIS), and globally distributed Aerosol Robotic Network\\n(AERONET) are compared. Comparison of the two datasets measurements for aerosol\\noptical depth values show that there are biases between the two data products.\\nIn this paper, we present a general framework towards identifying relevant set\\nof variables responsible for the observed bias. We present a general framework\\nto identify the possible factors influencing the bias, which might be\\nassociated with the measurement conditions such as the solar and sensor zenith\\nangles, the solar and sensor azimuth, scattering angles, and surface\\nreflectivity at the various measured wavelengths, etc. Specifically, we\\nperformed analysis for remote sensing Aqua-Land data set, and used machine\\nlearning technique, neural network in this case, to perform multivariate\\nregression between the ground-truth and the training data sets. Finally, we\\nused mutual information between the observed and the predicted values as the\\nmeasure of similarity to identify the most relevant set of variables. The\\nsearch is brute force method as we have to consider all possible combinations.\\nThe computations involves a huge number crunching exercise, and we implemented\\nit by writing a job-parallel program.', 'author': [{'name': 'N. K. Malakar'}, {'name': 'D. J. Lary'}, {'name': 'D. Gencaga'}, {'name': 'A. Albayrak'}, {'name': 'J. Wei'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1063/1.4819985'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1063/1.4819985', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/1302.2969v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1302.2969v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9a6'), 'id': 'http://arxiv.org/abs/1302.3913v2', 'updated': '2014-01-17T05:06:04Z', 'published': '2013-02-15T23:49:21Z', 'title': 'Multiclass Data Segmentation using Diffuse Interface Methods on Graphs', 'summary': \"We present two graph-based algorithms for multiclass segmentation of\\nhigh-dimensional data. The algorithms use a diffuse interface model based on\\nthe Ginzburg-Landau functional, related to total variation compressed sensing\\nand image processing. A multiclass extension is introduced using the Gibbs\\nsimplex, with the functional's double-well potential modified to handle the\\nmulticlass case. The first algorithm minimizes the functional using a convex\\nsplitting numerical scheme. The second algorithm is a uses a graph adaptation\\nof the classical numerical Merriman-Bence-Osher (MBO) scheme, which alternates\\nbetween diffusion and thresholding. We demonstrate the performance of both\\nalgorithms experimentally on synthetic data, grayscale and color images, and\\nseveral benchmark data sets such as MNIST, COIL and WebKB. We also make use of\\nfast numerical solvers for finding the eigenvectors and eigenvalues of the\\ngraph Laplacian, and take advantage of the sparsity of the matrix. Experiments\\nindicate that the results are competitive with or better than the current\\nstate-of-the-art multiclass segmentation algorithms.\", 'author': [{'name': 'Cristina Garcia-Cardona'}, {'name': 'Ekaterina Merkurjev'}, {'name': 'Andrea L. Bertozzi'}, {'name': 'Arjuna Flenner'}, {'name': 'Allon Percus'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '14 pages'}, 'link': [{'@href': 'http://arxiv.org/abs/1302.3913v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1302.3913v2', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': '62-XX', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9a9'), 'id': 'http://arxiv.org/abs/1302.6766v3', 'updated': '2016-12-14T08:47:37Z', 'published': '2013-02-27T13:41:44Z', 'title': 'A bag-of-paths framework for network data analysis', 'summary': 'This work develops a generic framework, called the bag-of-paths (BoP), for\\nlink and network data analysis. The central idea is to assign a probability\\ndistribution on the set of all paths in a network. More precisely, a\\nGibbs-Boltzmann distribution is defined over a bag of paths in a network, that\\nis, on a representation that considers all paths independently. We show that,\\nunder this distribution, the probability of drawing a path connecting two nodes\\ncan easily be computed in closed form by simple matrix inversion. This\\nprobability captures a notion of relatedness between nodes of the graph: two\\nnodes are considered as highly related when they are connected by many,\\npreferably low-cost, paths. As an application, two families of distances\\nbetween nodes are derived from the BoP probabilities. Interestingly, the second\\ndistance family interpolates between the shortest path distance and the\\nresistance distance. In addition, it extends the Bellman-Ford formula for\\ncomputing the shortest path distance in order to integrate sub-optimal paths by\\nsimply replacing the minimum operator by the soft minimum operator.\\nExperimental results on semi-supervised classification show that both of the\\nnew distance families are competitive with other state-of-the-art approaches.\\nIn addition to the distance measures studied in this paper, the bag-of-paths\\nframework enables straightforward computation of many other relevant network\\nmeasures.', 'author': [{'name': 'Kevin Françoisse'}, {'name': 'Ilkka Kivimäki'}, {'name': 'Amin Mantrach'}, {'name': 'Fabrice Rossi'}, {'name': 'Marco Saerens'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1016/j.neunet.2017.03.010'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1016/j.neunet.2017.03.010', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/1302.6766v3', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1302.6766v3', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Manuscript submitted for publication'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Neural Networks, 90, pp. 90-111 (2017)'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9b6'), 'id': 'http://arxiv.org/abs/1304.6803v5', 'updated': '2014-01-01T07:13:09Z', 'published': '2013-04-25T05:37:55Z', 'title': 'Direct Learning of Sparse Changes in Markov Networks by Density Ratio\\n  Estimation', 'summary': 'We propose a new method for detecting changes in Markov network structure\\nbetween two sets of samples. Instead of naively fitting two Markov network\\nmodels separately to the two data sets and figuring out their difference, we\\n\\\\emph{directly} learn the network structure change by estimating the ratio of\\nMarkov network models. This density-ratio formulation naturally allows us to\\nintroduce sparsity in the network structure change, which highly contributes to\\nenhancing interpretability. Furthermore, computation of the normalization term,\\nwhich is a critical bottleneck of the naive approach, can be remarkably\\nmitigated. We also give the dual formulation of the optimization problem, which\\nfurther reduces the computation cost for large-scale Markov networks. Through\\nexperiments, we demonstrate the usefulness of our method.', 'author': [{'name': 'Song Liu'}, {'name': 'John A. Quinn'}, {'name': 'Michael U. Gutmann'}, {'name': 'Taiji Suzuki'}, {'name': 'Masashi Sugiyama'}], 'link': [{'@href': 'http://arxiv.org/abs/1304.6803v5', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1304.6803v5', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9d6'), 'id': 'http://arxiv.org/abs/1310.0532v4', 'updated': '2015-01-15T21:43:45Z', 'published': '2013-10-02T00:33:34Z', 'title': 'Perfect Clustering for Stochastic Blockmodel Graphs via Adjacency\\n  Spectral Embedding', 'summary': 'Vertex clustering in a stochastic blockmodel graph has wide applicability and\\nhas been the subject of extensive research. In thispaper, we provide a short\\nproof that the adjacency spectral embedding can be used to obtain perfect\\nclustering for the stochastic blockmodel and the degree-corrected stochastic\\nblockmodel. We also show an analogous result for the more general random dot\\nproduct graph model.', 'author': [{'name': 'Vince Lyzinski'}, {'name': 'Daniel Sussman'}, {'name': 'Minh Tang'}, {'name': 'Avanti Athreya'}, {'name': 'Carey Priebe'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '22 pages, including references; 2 figures'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Electronic Journal of Statistics, 8 (2014) 2905--2922'}, 'link': [{'@href': 'http://arxiv.org/abs/1310.0532v4', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1310.0532v4', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9df'), 'id': 'http://arxiv.org/abs/1310.5415v2', 'updated': '2014-03-25T01:45:43Z', 'published': '2013-10-21T04:03:46Z', 'title': 'Disease Prediction based on Functional Connectomes using a Scalable and\\n  Spatially-Informed Support Vector Machine', 'summary': 'Substantial evidence indicates that major psychiatric disorders are\\nassociated with distributed neural dysconnectivity, leading to strong interest\\nin using neuroimaging methods to accurately predict disorder status. In this\\nwork, we are specifically interested in a multivariate approach that uses\\nfeatures derived from whole-brain resting state functional connectomes.\\nHowever, functional connectomes reside in a high dimensional space, which\\ncomplicates model interpretation and introduces numerous statistical and\\ncomputational challenges. Traditional feature selection techniques are used to\\nreduce data dimensionality, but are blind to the spatial structure of the\\nconnectomes. We propose a regularization framework where the 6-D structure of\\nthe functional connectome is explicitly taken into account via the fused Lasso\\nor the GraphNet regularizer. Our method only restricts the loss function to be\\nconvex and margin-based, allowing non-differentiable loss functions such as the\\nhinge-loss to be used. Using the fused Lasso or GraphNet regularizer with the\\nhinge-loss leads to a structured sparse support vector machine (SVM) with\\nembedded feature selection. We introduce a novel efficient optimization\\nalgorithm based on the augmented Lagrangian and the classical alternating\\ndirection method, which can solve both fused Lasso and GraphNet regularized SVM\\nwith very little modification. We also demonstrate that the inner subproblems\\nof the algorithm can be solved efficiently in analytic form by coupling the\\nvariable splitting strategy with a data augmentation scheme. Experiments on\\nsimulated data and resting state scans from a large schizophrenia dataset show\\nthat our proposed approach can identify predictive regions that are spatially\\ncontiguous in the 6-D \"connectome space,\" offering an additional layer of\\ninterpretability that could provide new insights about various disease\\nprocesses.', 'author': [{'name': 'Takanori Watanabe'}, {'name': 'Daniel Kessler'}, {'name': 'Clayton Scott'}, {'name': 'Michael Angstadt'}, {'name': 'Chandra Sripada'}], 'link': [{'@href': 'http://arxiv.org/abs/1310.5415v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1310.5415v2', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdf9e5'), 'id': 'http://arxiv.org/abs/1310.6319v2', 'updated': '2014-05-29T19:20:14Z', 'published': '2013-10-23T18:27:42Z', 'title': 'Efficient State-Space Inference of Periodic Latent Force Models', 'summary': 'Latent force models (LFM) are principled approaches to incorporating\\nsolutions to differential equations within non-parametric inference methods.\\nUnfortunately, the development and application of LFMs can be inhibited by\\ntheir computational cost, especially when closed-form solutions for the LFM are\\nunavailable, as is the case in many real world problems where these latent\\nforces exhibit periodic behaviour. Given this, we develop a new sparse\\nrepresentation of LFMs which considerably improves their computational\\nefficiency, as well as broadening their applicability, in a principled way, to\\ndomains with periodic or near periodic latent forces. Our approach uses a\\nlinear basis model to approximate one generative model for each periodic force.\\nWe assume that the latent forces are generated from Gaussian process priors and\\ndevelop a linear basis model which fully expresses these priors. We apply our\\napproach to model the thermal dynamics of domestic buildings and show that it\\nis effective at predicting day-ahead temperatures within the homes. We also\\napply our approach within queueing theory in which quasi-periodic arrival rates\\nare modelled as latent forces. In both cases, we demonstrate that our approach\\ncan be implemented efficiently using state-space methods which encode the\\nlinear dynamic systems via LFMs. Further, we show that state estimates obtained\\nusing periodic latent force models can reduce the root mean squared error to\\n17% of that from non-periodic models and 27% of the nearest rival approach\\nwhich is the resonator model.', 'author': [{'name': 'Steven Reece'}, {'name': 'Stephen Roberts'}, {'name': 'Siddhartha Ghosh'}, {'name': 'Alex Rogers'}, {'name': 'Nicholas Jennings'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '61 pages, 13 figures, accepted for publication in JMLR. Updates from\\n  earlier version occur throughout article in response to JMLR reviews'}, 'link': [{'@href': 'http://arxiv.org/abs/1310.6319v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1310.6319v2', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdfa2f'), 'id': 'http://arxiv.org/abs/1408.2714v2', 'updated': '2015-01-24T16:30:43Z', 'published': '2014-08-12T14:04:24Z', 'title': 'Learning From Non-iid Data: Fast Rates for the One-vs-All Multiclass\\n  Plug-in Classifiers', 'summary': \"We prove new fast learning rates for the one-vs-all multiclass plug-in\\nclassifiers trained either from exponentially strongly mixing data or from data\\ngenerated by a converging drifting distribution. These are two typical\\nscenarios where training data are not iid. The learning rates are obtained\\nunder a multiclass version of Tsybakov's margin assumption, a type of low-noise\\nassumption, and do not depend on the number of classes. Our results are general\\nand include a previous result for binary-class plug-in classifiers with iid\\ndata as a special case. In contrast to previous works for least squares SVMs\\nunder the binary-class setting, our results retain the optimal learning rate in\\nthe iid case.\", 'author': [{'name': 'Vu Dinh'}, {'name': 'Lam Si Tung Ho'}, {'name': 'Nguyen Viet Cuong'}, {'name': 'Duy Nguyen'}, {'name': 'Binh T. Nguyen'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '12th Annual Conference on Theory and Applications of Models of\\n  Computation (TAMC 2015)'}, 'link': [{'@href': 'http://arxiv.org/abs/1408.2714v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1408.2714v2', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171301ea77f760e9fcdfa39'), 'id': 'http://arxiv.org/abs/1409.4011v1', 'updated': '2014-09-14T04:01:37Z', 'published': '2014-09-14T04:01:37Z', 'title': 'Raiders of the Lost Architecture: Kernels for Bayesian Optimization in\\n  Conditional Parameter Spaces', 'summary': 'In practical Bayesian optimization, we must often search over structures with\\ndiffering numbers of parameters. For instance, we may wish to search over\\nneural network architectures with an unknown number of layers. To relate\\nperformance data gathered for different architectures, we define a new kernel\\nfor conditional parameter spaces that explicitly includes information about\\nwhich parameters are relevant in a given structure. We show that this kernel\\nimproves model quality and Bayesian optimization results over several simpler\\nbaseline kernels.', 'author': [{'name': 'Kevin Swersky'}, {'name': 'David Duvenaud'}, {'name': 'Jasper Snoek'}, {'name': 'Frank Hutter'}, {'name': 'Michael A. Osborne'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '6 pages, 3 figures. Appeared in the NIPS 2013 workshop on Bayesian\\n  optimization'}, 'link': [{'@href': 'http://arxiv.org/abs/1409.4011v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1409.4011v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ML', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171304ba77f760e9fcdfa41'), 'id': 'http://arxiv.org/abs/math/0202274v1', 'updated': '2002-02-26T14:41:05Z', 'published': '2002-02-26T14:41:05Z', 'title': 'Estimation of Weibull Shape Parameter by Shrinkage Towards an Interval\\n  Under Failure Censored Sampling', 'summary': \"This paper is speculated to propose a class of shrinkage estimators for shape\\nparameter beta in failure censored samples from two-parameter Weibull\\ndistribution when some 'apriori' or guessed interval containing the parameter\\nbeta is available in addition to sample information and analyses their\\nproperties. Some estimators are generated from the proposed class and compared\\nwith the minimum mean squared error (MMSE) estimator. Numerical computations in\\nterms of percent relative efficiency and absolute relative bias indicate that\\ncertain of these estimators substantially improve the MMSE estimator in some\\nguessed interval of the parameter space of beta, especially for censored\\nsamples with small sizes. Subsequently, a modified class of shrinkage\\nestimators is proposed with its properties.\", 'author': [{'name': 'Housila P. Singh'}, {'name': 'Sharad Saxena'}, {'name': 'Jack Allen'}, {'name': 'Sarjinder Singh'}, {'name': 'Florentin Smarandache'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '20 pages, 2 tables, 1 figure'}, 'link': [{'@href': 'http://arxiv.org/abs/math/0202274v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/math/0202274v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'stat.TH', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': '62E17', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171304ba77f760e9fcdfbc1'), 'id': 'http://arxiv.org/abs/math/0606497v1', 'updated': '2006-06-20T11:51:51Z', 'published': '2006-06-20T11:51:51Z', 'title': 'Analyzing Incomplete Discrete Longitudinal Clinical Trial Data', 'summary': \"Commonly used methods to analyze incomplete longitudinal clinical trial data\\ninclude complete case analysis (CC) and last observation carried forward\\n(LOCF). However, such methods rest on strong assumptions, including missing\\ncompletely at random (MCAR) for CC and unchanging profile after dropout for\\nLOCF. Such assumptions are too strong to generally hold. Over the last decades,\\na number of full longitudinal data analysis methods have become available, such\\nas the linear mixed model for Gaussian outcomes, that are valid under the much\\nweaker missing at random (MAR) assumption. Such a method is useful, even if the\\nscientific question is in terms of a single time point, for example, the last\\nplanned measurement occasion, and it is generally consistent with the\\nintention-to-treat principle. The validity of such a method rests on the use of\\nmaximum likelihood, under which the missing data mechanism is ignorable as soon\\nas it is MAR. In this paper, we will focus on non-Gaussian outcomes, such as\\nbinary, categorical or count data. This setting is less straightforward since\\nthere is no unambiguous counterpart to the linear mixed model. We first provide\\nan overview of the various modeling frameworks for non-Gaussian longitudinal\\ndata, and subsequently focus on generalized linear mixed-effects models, on the\\none hand, of which the parameters can be estimated using full likelihood, and\\non generalized estimating equations, on the other hand, which is a\\nnonlikelihood method and hence requires a modification to be valid under MAR.\\nWe briefly comment on the position of models that assume missingness not at\\nrandom and argue they are most useful to perform sensitivity analysis. Our\\ndevelopments are underscored using data from two studies. While the case\\nstudies feature binary outcomes, the methodology applies equally well to other\\ndiscrete-data settings, hence the qualifier ``discrete'' in the title.\", 'author': [{'name': 'Ivy Jansen'}, {'name': 'Caroline Beunckens'}, {'name': 'Geert Molenberghs'}, {'name': 'Geert Verbeke'}, {'name': 'Craig Mallinckrodt'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/088342305000000322'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/088342305000000322', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/math/0606497v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/math/0606497v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published at http://dx.doi.org/10.1214/088342305000000322 in the\\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Statistical Science 2006, Vol. 21, No. 1, 52-69'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'stat.TH', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171304ba77f760e9fcdfc94'), 'id': 'http://arxiv.org/abs/math/0701243v1', 'updated': '2007-01-09T06:18:45Z', 'published': '2007-01-09T06:18:45Z', 'title': 'A General Family of Estimators for Estimating Population Mean Using\\n  Known Value of Some Population Parameter(s)', 'summary': 'A general family of estimators for estimating the population mean of the\\nvariable under study, which make use of known value of certain population\\nparameter(s), is proposed. Under Simple Random Sampling Without Replacement\\n(SRSWOR) scheme, the expressions of bias and mean-squared error (MSE) up to\\nfirst order of approximation are derived. Some well known estimators have been\\nshown as particular member of this family. An empirical study is carried out to\\nillustrate the performance of the constructed estimator over others.', 'author': [{'name': 'M. Khoshnevisan'}, {'name': 'Rajesh Singh'}, {'name': 'Pankaj Chauhan'}, {'name': 'Nirmala Sawan'}, {'name': 'Florentin Smarandache'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '11 pages'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Far East Journal of Theoretical Statistics, Vol. 22, No. 2, pp.\\n  181-191, 2007'}, 'link': [{'@href': 'http://arxiv.org/abs/math/0701243v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/math/0701243v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'stat.TH', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': '92B28, 62P20', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171304ba77f760e9fcdfcb0'), 'id': 'http://arxiv.org/abs/math/0702225v1', 'updated': '2007-02-08T16:24:50Z', 'published': '2007-02-08T16:24:50Z', 'title': 'Bayesian Inference for Linear Dynamic Models with Dirichlet Process\\n  Mixtures', 'summary': 'Using Kalman techniques, it is possible to perform optimal estimation in\\nlinear Gaussian state-space models. We address here the case where the noise\\nprobability density functions are of unknown functional form. A flexible\\nBayesian nonparametric noise model based on Dirichlet process mixtures is\\nintroduced. Efficient Markov chain Monte Carlo and Sequential Monte Carlo\\nmethods are then developed to perform optimal batch and sequential estimation\\nin such contexts. The algorithms are applied to blind deconvolution and change\\npoint detection. Experimental results on synthetic and real data demonstrate\\nthe efficiency of this approach in various contexts.', 'author': [{'name': 'François Caron', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'INRIA Futurs'}}, {'name': 'Manuel Davy', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'INRIA Futurs'}}, {'name': 'Arnaud Doucet', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'INRIA Futurs'}}, {'name': 'Emmanuel Duflos', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'INRIA Futurs'}}, {'name': 'Philippe Vanheeghe', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'INRIA Futurs'}}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1109/TSP.2007.900167'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1109/TSP.2007.900167', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/math/0702225v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/math/0702225v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'IEEE Transactions on Signal Processing (2006)'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'stat.TH', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171304ba77f760e9fcdfd3f'), 'id': 'http://arxiv.org/abs/0708.1054v1', 'updated': '2007-08-08T07:32:27Z', 'published': '2007-08-08T07:32:27Z', 'title': 'Shape restricted regression with random Bernstein polynomials', 'summary': 'Shape restricted regressions, including isotonic regression and concave\\nregression as special cases, are studied using priors on Bernstein polynomials\\nand Markov chain Monte Carlo methods. These priors have large supports, select\\nonly smooth functions, can easily incorporate geometric information into the\\nprior, and can be generated without computational difficulty. Algorithms\\ngenerating priors and posteriors are proposed, and simulation studies are\\nconducted to illustrate the performance of this approach. Comparisons with the\\ndensity-regression method of Dette et al. (2006) are included.', 'author': [{'name': 'I-Shou Chang'}, {'name': 'Li-Chu Chien'}, {'name': 'Chao A. Hsiung'}, {'name': 'Chi-Chung Wen'}, {'name': 'Yuh-Jenn Wu'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/074921707000000157'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/074921707000000157', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0708.1054v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0708.1054v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published at http://dx.doi.org/10.1214/074921707000000157 in the IMS\\n  Lecture Notes Monograph Series\\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'IMS Lecture Notes Monograph Series 2007, Vol. 54, 187-202'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'stat.TH', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': '62F15, 62G08 (Primary) 65D10 (Secondary)', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171304ba77f760e9fcdfd73'), 'id': 'http://arxiv.org/abs/0709.1648v1', 'updated': '2007-09-11T15:01:39Z', 'published': '2007-09-11T15:01:39Z', 'title': 'Asymptotics: Particles, Processes and Inverse Problems. Festschrift for\\n  Piet Groeneboom', 'summary': \"In September 2006, Piet Groeneboom officially retired as professor of\\nstatistics at Delft University of Technology and the Vrije Universiteit in\\nAmsterdam. He did so by delivering his farewell lecture `Summa Cogitatio' ([42]\\nin Piet's publication list) in the Aula of the university in Delft. To\\ncelebrate Piet's impressive contributions to statistics and probability, the\\nworkshop `Asymptotics: particles, processes and inverse problems' was held from\\nJuly 10 until July 14, 2006, at the Lorentz Center in Leiden. Many leading\\nresearchers in the fields of probability and statistics gave talks at this\\nworkshop, and it became a memorable event for all who attended, including the\\norganizers and Piet himself. This volume serves as a Festschrift for Piet\\nGroeneboom. It contains papers that were presented at the workshop as well as\\nsome other contributions, and it represents the state of the art in the areas\\nin statistics and probability where Piet has been (and still is) most active.\\nFurthermore, a short CV of Piet Groeneboom and a list of his publications are\\nincluded.\", 'author': [{'name': 'Eric A. Cator'}, {'name': 'Geurt Jongbloed'}, {'name': 'Cor Kraaikamp'}, {'name': 'Hendrik P. Lopuhaä'}, {'name': 'Jon A. Wellner'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/074921707000000247'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/074921707000000247', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0709.1648v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0709.1648v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published at http://dx.doi.org/10.1214/074921707000000247 in the IMS\\n  Lecture Notes Monograph Series\\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'IMS Lecture Notes Monograph Series 2007, Vol. 55, i-xii'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'math.ST', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'stat.TH', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171305ba77f760e9fcdfe50'), 'id': 'http://arxiv.org/abs/0708.3796v1', 'updated': '2007-08-28T14:22:23Z', 'published': '2007-08-28T14:22:23Z', 'title': 'Embedding Population Dynamics Models in Inference', 'summary': \"Increasing pressures on the environment are generating an ever-increasing\\nneed to manage animal and plant populations sustainably, and to protect and\\nrebuild endangered populations. Effective management requires reliable\\nmathematical models, so that the effects of management action can be predicted,\\nand the uncertainty in these predictions quantified. These models must be able\\nto predict the response of populations to anthropogenic change, while handling\\nthe major sources of uncertainty. We describe a simple ``building block''\\napproach to formulating discrete-time models. We show how to estimate the\\nparameters of such models from time series of data, and how to quantify\\nuncertainty in those estimates and in numbers of individuals of different types\\nin populations, using computer-intensive Bayesian methods. We also discuss\\nadvantages and pitfalls of the approach, and give an example using the British\\ngrey seal population.\", 'author': [{'name': 'Stephen T. Buckland'}, {'name': 'Ken B. Newman'}, {'name': 'Carmen Fernández'}, {'name': 'Len Thomas'}, {'name': 'John Harwood'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/088342306000000673'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/088342306000000673', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/0708.3796v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0708.3796v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published at http://dx.doi.org/10.1214/088342306000000673 in the\\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\\n  Mathematical Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Statistical Science 2007, Vol. 22, No. 1, 44-58'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171305ba77f760e9fcdfe5b'), 'id': 'http://arxiv.org/abs/0709.3545v1', 'updated': '2007-09-21T22:48:10Z', 'published': '2007-09-21T22:48:10Z', 'title': 'Locally Adaptive Nonparametric Binary Regression', 'summary': 'A nonparametric and locally adaptive Bayesian estimator is proposed for\\nestimating a binary regression. Flexibility is obtained by modeling the binary\\nregression as a mixture of probit regressions with the argument of each probit\\nregression having a thin plate spline prior with its own smoothing parameter\\nand with the mixture weights depending on the covariates. The estimator is\\ncompared to a single spline estimator and to a recently proposed locally\\nadaptive estimator. The methodology is illustrated by applying it to both\\nsimulated and real examples.', 'author': [{'name': 'Sally Wood'}, {'name': 'Robert Kohn'}, {'name': 'Remy Cottet'}, {'name': 'Wenxin Jiang'}, {'name': 'Martin Tanner'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '31 pages, 10 figures'}, 'link': [{'@href': 'http://arxiv.org/abs/0709.3545v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0709.3545v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171305ba77f760e9fcdfea3'), 'id': 'http://arxiv.org/abs/0807.4086v1', 'updated': '2008-07-25T12:36:09Z', 'published': '2008-07-25T12:36:09Z', 'title': 'Estimating a difference between Kullback-Leibler risks by a normalized\\n  difference of AIC', 'summary': 'AIC is commonly used for model selection but the precise value of AIC has no\\ndirect interpretation. We are interested in quantifying a difference of risks\\nbetween two models. This may be useful for both an explanatory point of view or\\nfor prediction, where a simpler model may be preferred if it does nearly as\\nwell as a more complex model. The difference of risks can be interpreted by\\nlinking the risks with relative errors in the computation of probabilities and\\nlooking at the values obtained for simple models. A scale of values going from\\nnegligible to large is proposed. We propose a normalization of a difference of\\nAkaike criteria for estimating the difference of expected Kullback-Leibler\\nrisks between maximum likelihood estimators of the distribution in two\\ndifferent models. The variability of this statistic can be estimated. Thus, an\\ninterval can be constructed which contains the true difference of expected\\nKullback-Leibler risks with a pre-specified probability. A simulation study\\nshows that the method works and it is illustrated on two examples. The first is\\na study of the relationship between body-mass index and depression in elderly\\npeople. The second is the choice between models of HIV dynamics, where one\\nmodel makes the distinction between activated CD4+ T lymphocytes and the other\\ndoes not.', 'author': [{'name': 'D. Commenges'}, {'name': 'A. Sayyareh'}, {'name': 'L. Letenneur'}, {'name': 'J. Guedj'}, {'name': 'A. Bar-Hen'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '36 pages'}, 'link': [{'@href': 'http://arxiv.org/abs/0807.4086v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0807.4086v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': [{'@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': '62P10; 82B10', '@scheme': 'http://arxiv.org/schemas/atom'}]}\n",
      "{'_id': ObjectId('6171305ba77f760e9fcdfeb4'), 'id': 'http://arxiv.org/abs/0808.3055v1', 'updated': '2008-08-22T17:00:32Z', 'published': '2008-08-22T17:00:32Z', 'title': 'Minimal average degree aberration and the state polytope for\\n  experimental designs', 'summary': 'For a particular experimental design, there is interest in finding which\\npolynomial models can be identified in the usual regression set up. The\\nalgebraic methods based on Groebner bases provide a systematic way of doing\\nthis. The algebraic method does not in general produce all estimable models but\\nit can be shown that it yields models which have minimal average degree in a\\nwell-defined sense and in both a weighted and unweighted version. This provides\\nan alternative measure to that based on \"aberration\" and moreover is applicable\\nto any experimental design. A simple algorithm is given and bounds are derived\\nfor the criteria, which may be used to give asymptotic Nyquist-like\\nestimability rates as model and sample sizes increase.', 'author': [{'name': 'Yael Berstein'}, {'name': 'Hugo Maruri-Aguilar'}, {'name': 'Shmuel Onn'}, {'name': 'Eva Riccomagno'}, {'name': 'Henry Wynn'}], 'link': [{'@href': 'http://arxiv.org/abs/0808.3055v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/0808.3055v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171305ba77f760e9fcdff23'), 'id': 'http://arxiv.org/abs/1003.0188v1', 'updated': '2010-02-28T16:11:25Z', 'published': '2010-02-28T16:11:25Z', 'title': 'History of applications of martingales in survival analysis', 'summary': \"The paper traces the development of the use of martingale methods in survival\\nanalysis from the mid 1970's to the early 1990's. This development was\\ninitiated by Aalen's Berkeley PhD-thesis in 1975, progressed through the work\\non estimation of Markov transition probabilities, non-parametric tests and\\nCox's regression model in the late 1970's and early 1980's, and it was\\nconsolidated in the early 1990's with the publication of the monographs by\\nFleming and Harrington (1991) and Andersen, Borgan, Gill and Keiding (1993).\\nThe development was made possible by an unusually fast technology transfer of\\npure mathematical concepts, primarily from French probability, into practical\\nbiostatistical methodology, and we attempt to outline some of the personal\\nrelationships that helped this happen. We also point out that survival analysis\\nwas ready for this development since the martingale ideas inherent in the deep\\nunderstanding of temporal development so intrinsic to the French theory of\\nprocesses were already quite close to the surface in survival analysis.\", 'author': [{'name': 'Odd O. Aalen'}, {'name': 'Per Kragh Andersen'}, {'name': 'Ørnulf Borgan'}, {'name': 'Richard D. Gill'}, {'name': 'Niels Keiding'}], 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Electronic Journal for History of Probability and Statistics, Vol.\\n  5, Nr. 1, June 2009 (www.jehps.net), 28 pp'}, 'link': [{'@href': 'http://arxiv.org/abs/1003.0188v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1003.0188v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171305ba77f760e9fcdff57'), 'id': 'http://arxiv.org/abs/1010.0173v2', 'updated': '2011-04-12T12:56:31Z', 'published': '2010-10-01T14:33:45Z', 'title': 'Validated Intraclass Correlation Statistics to Test Item Performance\\n  Models', 'summary': 'A new method, with an application program in Matlab code, is proposed for\\ntesting item performance models on empirical databases. This method uses data\\nintraclass correlation statistics as expected correlations to which one\\ncompares simple functions of correlations between model predictions and\\nobserved item performance. The method rests on a data population model whose\\nvalidity for the considered data is suitably tested, and has been verified for\\nthree behavioural measure databases. Contrarily to usual model selection\\ncriteria, this method provides an effective way of testing under-fitting and\\nover-fitting, answering the usually neglected question \"does this model\\nsuitably account for these data?\"', 'author': [{'name': 'Pierre Courrieu', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'LPC'}}, {'name': \"Muriele Brand-D'Abrescia\", 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'LEAD'}}, {'name': 'Ronald Peereman', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'LPNC'}}, {'name': 'Daniel Spieler', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'LPC'}}, {'name': 'Arnaud Rey', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'LPC'}}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.3758/s13428-010-0020-5'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.3758/s13428-010-0020-5', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/1010.0173v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1010.0173v2', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Behavior Research Methods 43, 1 (2011) pp. 37-55, DOI\\n  10.3758/s13428-010-0020-5'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}}\n",
      "{'_id': ObjectId('6171305ba77f760e9fcdff69'), 'id': 'http://arxiv.org/abs/1010.5091v1', 'updated': '2010-10-25T11:19:57Z', 'published': '2010-10-25T11:19:57Z', 'title': 'Robust Tests in Genome-Wide Scans under Incomplete Linkage\\n  Disequilibrium', 'summary': \"Under complete linkage disequilibrium (LD), robust tests often have greater\\npower than Pearson's chi-square test and trend tests for the analysis of\\ncase-control genetic association studies. Robust statistics have been used in\\ncandidate-gene and genome-wide association studies (GWAS) when the genetic\\nmodel is unknown. We consider here a more general incomplete LD model, and\\nexamine the impact of penetrances at the marker locus when the genetic models\\nare defined at the disease locus. Robust statistics are then reviewed and their\\nefficiency and robustness are compared through simulations in GWAS of 300,000\\nmarkers under the incomplete LD model. Applications of several robust tests to\\nthe Wellcome Trust Case-Control Consortium [Nature 447 (2007) 661--678] are\\npresented.\", 'author': [{'name': 'Gang Zheng'}, {'name': 'Jungnam Joo'}, {'name': 'Dmitri Zaykin'}, {'name': 'Colin Wu'}, {'name': 'Nancy Geller'}], 'arxiv:doi': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10.1214/09-STS314'}, 'link': [{'@title': 'doi', '@href': 'http://dx.doi.org/10.1214/09-STS314', '@rel': 'related'}, {'@href': 'http://arxiv.org/abs/1010.5091v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/1010.5091v1', '@rel': 'related', '@type': 'application/pdf'}], 'arxiv:comment': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Published in at http://dx.doi.org/10.1214/09-STS314 the Statistical\\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\\n  Statistics (http://www.imstat.org)'}, 'arxiv:journal_ref': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Statistical Science 2009, Vol. 24, No. 4, 503-516'}, 'arxiv:primary_category': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}, 'category': {'@term': 'stat.ME', '@scheme': 'http://arxiv.org/schemas/atom'}}\n"
     ]
    }
   ],
   "source": [
    "for doc in db.Statistics.find({'author': {'$size': 5}}):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ea8e6696542bf91b5850513673ceef1808937d627ee3e2c71e2007cafbd44d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('autodidact': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
