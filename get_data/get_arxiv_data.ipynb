{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, urllib.request\n",
    "import xmltodict\n",
    "import json\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Overview**\n",
    "\n",
    "Personally, I am a bit of an academic whom enjoys the research community and the exciting and new methods created and applied by the academic industry. When I am in the mood, I will often go to [arXiv](https://arxiv.org), an open access archive created and maintained by Cornell University for scholarly articles in the sciences, to read up on interesting new methods created and or applied within Computer Science, Statistics, Mathematics, and Economics. arXiv is vast, with nearly two million documents in their database. Thankfully they not only have a search engine for finding new papers, but also an API for retrieving scholarly articles within various categories according to their [taxonomy](https://arxiv.org/category_taxonomy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"/Users/wastechs/Documents/git-repos/arxiv_mongo/images/arxiv.png\" width=\"512\" height=\"174\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, I am interested in the taxonomies of:\n",
    "\n",
    "**Computer Science**\n",
    " - cs.AI = Artificial Intelligence\n",
    " - cs.CE = Computational Engineering\n",
    " - cs.DB = Databases\n",
    " - cs.ET = Emerging Technologies\n",
    " - cs.DC = Distributed Computing\n",
    " - cs.LG = Machine Learning\n",
    " - cs.IT = Information Theory\n",
    "\n",
    "**Statistics**\n",
    " - stat.AP = Statistical Applications\n",
    " - stat.ML = Machine Learning\n",
    " - stat.TH = Theory\n",
    " - stat.ME = Methodology\n",
    "\n",
    "**Mathematics**\n",
    " - math.PR = Probability Theory\n",
    " - math.ST = Mathematical Statistics\n",
    "\n",
    "**Economics**\n",
    " - econ.EM = Econometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to not only learn about MongoDB, but to also inform myself of relevant research articles in the areas I am interested in. However, due to the limiting factor of storage constraints on the free tier of MongoDB Atlas, only the top 1000 documents, **by relevance**, for each category were retrieved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ETL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Information\n",
    "cnx = 'mongodb+srv://gabe:gabe_mongo@arxiv.xawxi.mongodb.net/test'\n",
    "# Connection to MongoDB\n",
    "client = pymongo.MongoClient(cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Math', 'Economics', 'collection', 'Statistics', 'ComputerScience']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access 'arXiv' database\n",
    "db = client['arxiv']\n",
    "# I have already created my collections for the high level category taxonomies\n",
    "collections = db.list_collection_names()\n",
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fetch Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv category taxonomy for the \"for loop\"\n",
    "csCats = ['cs.AI', 'cs.CE', 'cs.DB', 'cs.ET', 'cs.DC', 'cs.LG', 'cs.IT']\n",
    "statCats = ['stat.AP', 'stat.ML', 'stat.TH', 'stat.ME']\n",
    "mathCats = ['math.PR', 'math.ST']\n",
    "econCats = ['econ.EM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arxiv(db, collection, category=list, file=bool):\n",
    "\n",
    "    if collection == 'Math':\n",
    "        col = db.Math\n",
    "    elif collection == 'ComputerScience':\n",
    "        col = db.ComputerScience\n",
    "    elif collection == 'Economics':\n",
    "        col = db.Economics\n",
    "    elif collection == 'Statistics':\n",
    "        col = db.Statistics\n",
    "    else:\n",
    "        raise ValueError('Collection not in MongoDB')\n",
    "\n",
    "    if type(category) != list:\n",
    "        raise TypeError('Category is not in list format')\n",
    "    else:\n",
    "        for cat in category:\n",
    "            url = 'http://export.arxiv.org/api/query?search_query=cat:{}&start=0&max_results=1000&sortBy=relevance&sortOrder=ascending'.format(cat)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            arxiv_data = data.read().decode('utf-8')\n",
    "\n",
    "            # Returned data is an \"Atom Document\" - convert to ordered dictionary\n",
    "            arxiv_dict = xmltodict.parse(arxiv_data)\n",
    "\n",
    "            # Converting to JSON\n",
    "            arxivJSON = json.dumps(arxiv_dict, indent=4)\n",
    "\n",
    "            # Decoding JSON\n",
    "            arxiv_final = json.loads(arxivJSON)\n",
    "\n",
    "            # Insert document into collection\n",
    "            try:\n",
    "                col.insert_many(arxiv_final['feed']['entry'])\n",
    "                print('Document {} inserted into {} collection'.format(cat, collection))\n",
    "            except:\n",
    "                print('An error has occured')\n",
    "\n",
    "            # Optional - write and save to file\n",
    "            if file == True:\n",
    "                with open('{}.json'.format(cat.replace('.', '_')), 'w') as write_file:\n",
    "                    json.dump(arxiv_dict, write_file, indent=4)\n",
    "\n",
    "    \n",
    "    return arxiv_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#math = get_arxiv(db, 'Math', mathCats, False)\n",
    "#cs = get_arxiv(db, 'ComputerScience', csCats, False)\n",
    "#stat = get_arxiv(db, 'Statistics', statCats, False)\n",
    "#econ = get_arxiv(db, 'Economics', econCats, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Document Structure**\n",
    "\n",
    "The documents returned by the arXiv API were straight away imported into their respective collection in the arXiv database. The class diagram below represents what a _single collection_ looks like. However, all collections have the same structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![class diagram](/Users/wastechs/Documents/git-repos/arxiv_mongo/images/class_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis**\n",
    "\n",
    "The queries designed here sometimes reflect my personal interests. For example, in regard to statistics, I classify myself as a Bayesian and thus, I have constructured a regex pipeline for finding any document containing Bayes, Bayesian, Bayesianism. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents in each collection\n",
    "db.Math.count_documents({}), db.ComputerScience.count_documents({}), db.Economics.count_documents({}), db.Statistics.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors with the most relevant papers in Computer Science\n",
    "c = db.ComputerScience.aggregate([\n",
    "    {'$project': {'_id': 0, 'author.name':1}},\n",
    "    {'$unwind': '$author.name'},\n",
    "    {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "    #{'sort': {'count': 1}} ## sort is not allowed in the Atlas tier\n",
    "])\n",
    "\n",
    "authors = pd.DataFrame(c)\n",
    "authors.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of my favorite machine learning researchers at the moment - Does he have any relevant papers?\n",
    "for doc in db.ComputerScience.aggregate([\n",
    "    {'$match': {'author.name': 'Kilian Q. Weinberger'}},\n",
    "    {'$project': {'title': 1, 'author.name': 1, '_id': 0}}]):\n",
    "\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics papers with \"Baye\" in the title\n",
    "for doc in db.Statistics.aggregate([\n",
    "    {'$project': {'_id': 0,\n",
    "                  'title': 1,\n",
    "                  'author.name': 1}},\n",
    "    {'$match': {'title': {'$regex': '^Bayes'}}}\n",
    "]):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematics and Computer Science complement each other very well\n",
    "stage_lookup = {\n",
    "    '$lookup': {\n",
    "        'from': 'Math',\n",
    "        'localField': 'author.name',\n",
    "        'foreignField': 'author.name',\n",
    "        'as': 'same_author'\n",
    "    }\n",
    "}\n",
    "\n",
    "match = {'$match': {'same_author.0': {'$exists': True}}}\n",
    "\n",
    "add_fields = {'$addFields': {\n",
    "    'author_name': 'author.name',\n",
    "    'paper_title': 'title'\n",
    "}}\n",
    "\n",
    "project = {'$project': {'_id': 0, 'author.name':1, 'title': 1}}\n",
    "\n",
    "unwind = {'$unwind': '$author.name'}\n",
    "\n",
    "group_by = {'$group': {'_id': '$author.name', 'count': {'$sum': 1}}}\n",
    "\n",
    "limit = {'$limit': 3}\n",
    "\n",
    "pipeline = [stage_lookup, match, project, add_fields, project, limit]\n",
    "#pipeline = [stage_lookup, match, project, unwind, group_by, limit]\n",
    "\n",
    "for doc in db.ComputerScience.aggregate(pipeline):\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ea8e6696542bf91b5850513673ceef1808937d627ee3e2c71e2007cafbd44d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('autodidact': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
